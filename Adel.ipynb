{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1T5o5647QxqV"
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import torch\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "from evaluate import load\n",
    "from transformers import DebertaV2Tokenizer, DebertaV2ForSequenceClassification, TrainingArguments, Trainer\n",
    "from datasets import load_dataset\n",
    "from huggingface_hub import notebook_login\n",
    "import sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tdHcQlf00VXT"
   },
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zUuGUm9C5ZZD"
   },
   "outputs": [],
   "source": [
    "main_dir = os.getenv(\"MAIN_DIR\")\n",
    "print(os.listdir(main_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FcBF6FPVikXu"
   },
   "outputs": [],
   "source": [
    "data_dir = main_dir + \"/liar2\"\n",
    "dataset = load_dataset(data_dir)\n",
    "model_dir = main_dir + \"/model_deberta_v3_xsmall\"\n",
    "tokenizer = DebertaV2Tokenizer.from_pretrained(model_dir)\n",
    "model = DebertaV2ForSequenceClassification.from_pretrained(\n",
    "    model_dir,\n",
    "    num_labels=6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f0XGlsnrkOvx"
   },
   "outputs": [],
   "source": [
    "def preprocess(examples):\n",
    "    return tokenizer(examples[\"statement\"], padding='max_length', truncation=True, max_length=128)\n",
    "\n",
    "tokenized_ds = dataset.map(preprocess, batched=True)\n",
    "tokenized_ds = tokenized_ds.rename_column(\"label\", \"labels\")\n",
    "tokenized_ds.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SZL_n8OiFV89"
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir= main_dir + \"/saved\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=4e-5,\n",
    "    per_device_train_batch_size=128,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=1,\n",
    "    load_best_model_at_end=True,\n",
    "    fp16=True,\n",
    "    #gradient_accumulation_steps=4,\n",
    "    dataloader_num_workers=8,\n",
    "    save_total_limit=2,\n",
    "    report_to=\"tensorboard\"\n",
    ")\n",
    "model.gradient_checkpointing_enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2A8sZvyou510"
   },
   "outputs": [],
   "source": [
    "lens = [len(x) for x in tokenized_ds['train']['input_ids']]\n",
    "print(tokenized_ds['train']['input_ids'])\n",
    "print(min(lens), max(lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xALrXLa65HOq"
   },
   "outputs": [],
   "source": [
    "labels = dataset['train']['label']\n",
    "class_weights = compute_class_weight(\"balanced\", classes=np.unique(labels), y=labels)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fpMkDtVFkyYt"
   },
   "outputs": [],
   "source": [
    "accuracy = load(\"accuracy\")\n",
    "f1 = load(\"f1\")\n",
    "precision = load(\"precision\")\n",
    "recall = load(\"recall\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    preds = np.argmax(predictions, axis=1)\n",
    "    acc = accuracy.compute(predictions=preds, references=labels)\n",
    "    f1_per_class = f1.compute(predictions=preds, references=labels, average=None)\n",
    "    precision_per_class = precision.compute(predictions=preds, references=labels, average=None)\n",
    "    recall_per_class = recall.compute(predictions=preds, references=labels, average=None)\n",
    "\n",
    "    # You can also compute macro/micro averages if you like:\n",
    "    f1_macro = f1.compute(predictions=preds, references=labels, average=\"macro\")[\"f1\"]\n",
    "    f1_micro = f1.compute(predictions=preds, references=labels, average=\"micro\")[\"f1\"]\n",
    "\n",
    "    # Prepare output\n",
    "    metrics = {\n",
    "        \"accuracy\": acc[\"accuracy\"],\n",
    "        \"f1_macro\": f1_macro,\n",
    "        \"f1_micro\": f1_micro,\n",
    "    }\n",
    "    # Add per-class metrics\n",
    "    for i, (f1c, prec, rec) in enumerate(zip(f1_per_class[\"f1\"], precision_per_class[\"precision\"], recall_per_class[\"recall\"])):\n",
    "        metrics[f\"f1_class_{i}\"] = f1c\n",
    "        metrics[f\"precision_class_{i}\"] = prec\n",
    "        metrics[f\"recall_class_{i}\"] = rec\n",
    "    return metrics\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_ds[\"train\"],\n",
    "    eval_dataset=tokenized_ds[\"validation\"],\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "o72X9BT0kCr1"
   },
   "outputs": [],
   "source": [
    "model.to(torch.device(\"cuda\"))\n",
    "res_before_train = trainer.evaluate(eval_dataset=tokenized_ds[\"validation\"])[\"eval_accuracy\"]\n",
    "print(res_before_train)\n",
    "trainer.train()\n",
    "res_after_train = trainer.evaluate(eval_dataset=tokenized_ds[\"validation\"])[\"eval_accuracy\"]\n",
    "if (res_before_train < res_after_train):\n",
    "  trainer.save_model(r\"\") # REMOVED PATH\n",
    "  print(f\"Improved by {res_after_train - res_before_train}\")\n",
    "else:\n",
    "  print(\"Didn't improve.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ly20MbrKkEeX"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "model.to(torch.device(\"cuda\"))\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f9-mky0aoAKh"
   },
   "outputs": [],
   "source": [
    "test_dir = r\"\" # REMOVED PATH\n",
    "test_tokenizer = AutoTokenizer.from_pretrained(test_dir)\n",
    "test_model = DebertaV2ForSequenceClassification.from_pretrained(test_dir)\n",
    "test_trainer = Trainer(model=test_model, tokenizer=test_tokenizer)\n",
    "metrics = trainer.evaluate(eval_dataset=tokenized_ds[\"test\"])\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B0my-jveTcsR"
   },
   "outputs": [],
   "source": [
    "# id2label = {0: \"Lie\",\n",
    "#             1: \"Deception by omission\",\n",
    "#             2: \"Denial\",\n",
    "#             3: \"An accusation of cowardice\",\n",
    "#             4: \"Rationalization\",\n",
    "#             5: \"Minimization\",\n",
    "#             6: \"Selective inattention\",\n",
    "#             7: \"Selective attention\",\n",
    "#             8: \"Distraction\",\n",
    "#             9: \"The excuse\",\n",
    "#             10: \"Hidden intimidation\",\n",
    "#             11: \"False guilt\",\n",
    "#             12: \"Attraction\",\n",
    "#             13: \"Victim's condemnation\",\n",
    "#             14: \"Playing the victim role\",\n",
    "#             15: \"Playing the role of a servant\",\n",
    "#             16: \"Seduction\",\n",
    "#             17: \"Projecting guilt\",\n",
    "#             18: \"Feigning innocence\",\n",
    "#             19: \"Simulation of confusion\",\n",
    "#             20: \"Aggressive anger\",\n",
    "#             21: \"Declassification\"}\n",
    "# label2id = {\"Lie\": 0,\n",
    "#             \"Deception by omission\": 1,\n",
    "#             \"Denial\": 2,\n",
    "#             \"An accusation of cowardice\": 3,\n",
    "#             \"Rationalization\": 4,\n",
    "#             \"Minimization\": 5,\n",
    "#             \"Selective inattention\": 6,\n",
    "#             \"Selective attention\": 7,\n",
    "#             \"Distraction\": 8,\n",
    "#             \"The excuse\": 9,\n",
    "#             \"Hidden intimidation\": 10,\n",
    "#             \"False guilt\": 11,\n",
    "#             \"Attraction\": 12,\n",
    "#             \"Victim's condemnation\": 13,\n",
    "#             \"Playing the victim role\": 14,\n",
    "#             \"Playing the role of a servant\": 15,\n",
    "#             \"Seduction\": 16,\n",
    "#             \"Projecting guilt\": 17,\n",
    "#             \"Feigning innocence\": 18,\n",
    "#             \"Simulation of confusion\": 19,\n",
    "#             \"Aggressive anger\": 20,\n",
    "#             \"Declassification\": 21}"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNlHYoPxC4bbMWjZLeWLZOk",
   "gpuType": "T4",
   "private_outputs": true,
   "provenance": [
    {
     "file_id": "1bh2dI2F5EdXq8rgLn3BYXgmfAx_TUeyk",
     "timestamp": 1750435267758
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
